#!/bin/bash


####
#### SCHEDULER DIRECTIVES 
####


#### Give the job a name, but keep it short
#PBS -N fmriprep_job

#### Select the queue for the job. Usually this will be set to the open account unless submitting to a paid compute allocation. Simply replace "open" with ID of paid allocation.
#PBS -A open

#### [ OPTIONAL ] Merge the output and input files
#PBS -j oe

##### Resource Request
#PBS -l nodes=1:ppn=4:stmem,mem=12gb,walltime=10:00

####  Resource Request Info
####    
####    #PBS -l nodes=<nodes>:ppn=<ppn>:<type>,<memory_spec>,<walltime_spec>
####    
####    Set size of resource request:
####    
####      nodes =  number of computing devices
####      ppn   =  processors/cores per node
####      
####        Note: Total Number of Processors Cores  =  nodes * ppn
####    
####        A node is essentially hardware that is connected together as a congruent computing device. Laptops, desktops, phones, and other computers could be viewed as a computational node. Somewhat "average" laptops nowadays may carry 4 or even 8 processors/cores, but nodes on Roar may have anywhere from 20 to 40 processors/cores depending upon the node type. The many nodes of Roar are connected to allow efficient communication between the nodes, and they are also mounted to the same filesystem. With proper configuration of academic and research software, a congruent computing device emerges out of this powerful connected network, and it is capable of reaching a high level of performance for many classes of computational problems.
####    
####    Request a specific node type:
####      
####      type  =  node type, dependent upon hardware configuration
####        
####        options
####        basic : basic node type.  good for general processing.
####        stmem : standard node type.  good for multiple-node jobs.
####        himem : high-memory node type. good for jobs with very large memory or ppn requirements.
####      
####    Specify memory with either mem or pmem:
####    
####      mem   = maximum amount of physical memory used by the job
####      pmem  = maximum amount of physical memory used by any single process of the job
####              
####        Note: Since pmem identifies the amount of memory per processor,
####                 Total Amount of Memory Per Node =  ppn * pmem
####    
####    Set a runtime limit for the job:
####    
####      walltime  =  maximum allowable time for this job to run in HH:MM:SS format
####    

####
####    Some Resource Request Guidelines:
####    
####    If no parallelization whatsoever is used in the job, use a single processor/core.
####    
####      #PBS -l nodes=1:ppn=1
####    
####    For general purpose computing, use roughly the same computing power as a good laptop might have.
####    
####      #PBS -l nodes=1:ppn=8
####      #PBS -l mem=32gb
####    
####    Utilizing the additional processors given to the job, however, requires that the applications running within the job can take advantage of parallel resources, either inherently or by proper configuration. If the job is not configured to use the additional processors, then unutilized processors will remain idle for the duration of the job.
####    
####    For scaling up to multi-node jobs, the software must be specifically configured in order to utilize and coordinate the multiple nodes. This level of configuration signifcantly boosts the job's scalability. The standard and high memory nodes are connected with infiniband cables and also via ethernet. The basic nodes are only connected via ethernet. Multi-node jobs will typically benefit from specifically running on nodes connected with infiniband.
####      #PBS -l nodes=3:ppn=4:stmem
####    
####    For a gpu job, add gpus to the resource request:
####      #PBS -A <paid_gpu_alloc_id>
####      #PBS -l nodes=1:ppn=4:gpus=1
####    
####    In general, reduce the overall resource footprint of your job for fast placement. As a rule of thumb, calculate your best possible estimate for the job's memory and time requirements then add a 20% - 50% margin to select the memory and time request. Improve this estimate iteratively on subsequent jobs. The open account has a maximum allowable walltime of 48 hours.



####
#### MAIN JOB SCRIPT
####


# Get the job started and start the clock
start=`date +%s`
jobid=$(echo $PBS_JOBID | awk -F '.' '{print $1}')
echo "Job ${jobid} started at `date` on `hostname`"

cd $PBS_O_WORKDIR
    #  PBS_O_WORKDIR is the absolute path of the current working directory of the qsub command
    #  The session launches in $HOME by default, so must navigate the session to the original submission directory 

#### SET UP SOFTWARE ENVIRONMENT


# Verify environment and software configuration
if [ ! -f "${fmriprep_base}/fmriprep-${fmriprep_version}.simg" ] ; then
    echo " ERROR:  Container fmriprep-${fmriprep_version}.simg not found!"
    echo "         Please change the version or build fmriprep-${fmriprep_version}.simg, then try again."
fi


#### RUN THE JOB
hostname


#### POST-PROCESS

# Collect relevant job info

# Print out final report

# Clean up

# Finalize job
echo "Job ended at `date`"
end=`date +%s`
runtime=$((end-start))
echo "Job runtime =  ${runtime}  seconds"

